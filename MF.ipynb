{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wujingyi/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/wujingyi/miniconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/Users/wujingyi/miniconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import scipy\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/cleaned_train_2.csv', \n",
    "                 header = 0, \n",
    "                 names = ['user', 'movie','rating'], \n",
    "                 usecols = [0,1,2])\n",
    "\n",
    "test_df = pd.read_csv('./dataset/cleaned_test_2.csv', \n",
    "                 header = 0, \n",
    "                 names = ['user', 'movie','rating'], \n",
    "                 usecols = [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, user_item_pairs, ratings):\n",
    "        'Initialization'\n",
    "        self.labels  = ratings\n",
    "        self.samples = user_item_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # # Load data and get label\n",
    "        #print(\"called get item\")\n",
    "        user_item_pair = self.samples[index].astype('long')\n",
    "        user_social = np.zeros(64).astype('long') #convert to actual social embeddings later\n",
    "        user_item_pair_social = np.concatenate((user_item_pair, user_social), axis=None)\n",
    "        X = user_item_pair_social\n",
    "        y = self.labels[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items,latent_dim=8,layers = [16,32,16,8]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
    "        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(in_features=layers[-1], out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "#         print(\"item_embedding\")\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        \n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\n",
    "#         print(\"vector\",vector)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = torch.nn.ReLU()(vector)\n",
    "            # vector = torch.nn.BatchNorm1d()(vector)\n",
    "            # vector = torch.nn.Dropout(p=0.5)(vector)\n",
    "        out = self.affine_output(vector)\n",
    "#         rating = self.logistic(logits)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    print(np.array([y_preds,y_actuals]))\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epoch_run(model, generator, opt, criterion, mode=\"train\"):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    #for local_batch, local_labels in generator:\n",
    "    for local_batch, local_labels  in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        \n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        \n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        \n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            print(\"loss:\",loss)\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(df):\n",
    "    df[['rating']]=df[['rating']].astype(float)\n",
    "    df[['user']]=df[['user']].astype(int)\n",
    "    df[['movie']]=df[['movie']].astype(int)\n",
    "    \n",
    "    user_id = df[['user']].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "    item_id = df[['movie']].drop_duplicates()\n",
    "    user_id.rename(columns={'index':'user_id'},inplace=True)\n",
    "    subset = df.merge(user_id,\"left\",on = \"user\")[['user_id', 'movie', 'rating']]\n",
    "    \n",
    "#     print(subset)\n",
    "    num_users = int(len(user_id)+1)\n",
    "#     num_users = int(user_id['user'].max() - user_id['user'].min() + 1)\n",
    "    num_items = int(item_id['movie'].max()  + 1)\n",
    "    # num_items = int(len(item_id))\n",
    "    print(\"num_users: \",num_users,\"num_items: \", num_items)\n",
    "    \n",
    "#     subset = df[['user', 'movie', 'rating']]\n",
    "    total_ratings = np.array(subset.values)\n",
    "    user_item_pairs = total_ratings[:,0:2]\n",
    "    ratings = total_ratings[:,2:3]\n",
    "    return total_ratings,user_item_pairs,ratings,num_users,num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepro(train_df[900:1000])\n",
    "# train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10240\n",
    "EPOCH = 100\n",
    "training_params = {'batch_size': BATCH_SIZE,'shuffle': True,'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:  131099 num_items:  4500\n",
      "num_users:  14567 num_items:  4500\n"
     ]
    }
   ],
   "source": [
    "total_ratings,user_item_pairs,ratings,num_users,num_items = prepro(train_df)\n",
    "train_dataset = Dataset(user_item_pairs,ratings)\n",
    "total_ratings_test,user_item_pairs_test,ratings_test,_,_ = prepro(test_df)\n",
    "test_dataset = Dataset(user_item_pairs_test,ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = torch.utils.data.DataLoader(train_dataset, **training_params)\n",
    "test_generator = torch.utils.data.DataLoader(test_dataset, **training_params)\n",
    "\n",
    "model = MLP(num_users,num_items).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ll = None\n",
    "# for local_batch, local_labels  in train_generator:\n",
    "# #     print(local_batch)\n",
    "# #     print(local_batch[:,0])\n",
    "# #     print(local_batch[:,1])\n",
    "# #     print(local_batch[:,2])\n",
    "#     ll = local_batch\n",
    "#     y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "#     print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "t loss:  1.4815840749005265\n",
      "epoch:  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-20fcf5939671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-caedd69183f8>\u001b[0m in \u001b[0;36mepoch_run\u001b[0;34m(model, generator, opt, criterion, mode)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         print(\"loss:\",loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_ = []\n",
    "loss_t = []\n",
    "for epoch in range(EPOCH):\n",
    "    print(\"epoch: \", epoch)\n",
    "    train_mse = epoch_run(model, train_generator, opt, criterion,\"train\")\n",
    "    val_mse = epoch_run(model, test_generator, opt, criterion, \"val\")\n",
    "    loss_.append(train_mse)\n",
    "    loss_t.append(val_mse)\n",
    "    print(\"train loss: \", train_mse)\n",
    "    print(\"val loss: \", val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = len(loss_)\n",
    "# MSE plot\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax3 = ax2.twinx()\n",
    "lns2 = ax2.plot(np.arange(eps), loss_, label=\"Loss\")\n",
    "lns3 = ax3.plot(np.arange(eps), loss_t, label=\"Loss\")\n",
    "\n",
    "ax2.set_xlabel('iteration')\n",
    "ax2.set_ylabel('training mse')\n",
    "ax3.set_ylabel('val mse')\n",
    "lns = lns3 + lns2\n",
    "labels = [\"train mse\", \"val mse\"]\n",
    "plt.legend(lns, labels, loc=7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model,test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "torch.save(model.state_dict(), './models/mfmlp.pkl')\n",
    "# 加载\n",
    "# model = TheModelClass(...)\n",
    "# model.load_state_dict(torch.load('\\parameter.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
