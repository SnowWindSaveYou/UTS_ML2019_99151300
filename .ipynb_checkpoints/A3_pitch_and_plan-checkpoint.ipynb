{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Teleprompter using Speech Recognition Model\n",
    "Jingyi Wu 99151300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductionn\n",
    "The speech is one very normal thing in life, people always need to speech for some things such as for the proposal, for sale, and for teaching. However, the speech also is a hard thing for many people, and they are usually feeling the tension even forgot the word at speech. Because the reason of that if they are chosen to reading speech note they will lose the audience impression or mark, therefore most people are chosen to release from note, but the problem of forgot word is still exist, and when they were released from note, once if they forget words and want to find where they are current specking, then they will spend long time on find where are they speaking at note, that behaviour breaks their rhythm of speech and damage to their audience impression also waste the time of speech. Evidently, there is a requirement of an application that can remind speech following the user’s speech progress.\n",
    " \n",
    "In this case, the aim of my proposal project is to implements an intelligent teleprompter which can intelligently remind the user where is his current speech location at his speech note, to achieve the goal of help user can do a better speech. This aim can be divided into several objectives: \n",
    "\n",
    "1) Develop several speech recognitions models those can locate the position of input voice steam at speech note. \n",
    "\n",
    "2) Evaluate the model and analysis. \n",
    "\n",
    "3) Deploy the speech recognition model and develop mobile and desktop clients. \n",
    "\n",
    "4) Improve the interaction design of clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Since the requirement of speech reminding, there are many traditional methods such as automatic scroll and manually control, but one is limited at variable speed speech, and another is limited when not have a helper. In this case, to make an intelligent speech reminder is important, but there are only two known projects, one of them are developed by myself in early 2018, which is using existing speech recognition API with time-based weighting technique to achieve the function of tracking user speaking content at speech note, and Griffin (2019) also implement similar approach. While those development are both restricted users only can follow original speech note, if user speck many things out of speech or change the sentence form, those approached will hard to locate the position at speech note. Another problem is the processing time, and each time finish one sentence they require a few seconds for a response, which reduced considerable usability.\n",
    " \n",
    "The reason of those problems is that existing speech recognition model used are not developed for tracking speech, so that is not only needed to process extra tasks that waste computer resource and time, and also not meet the requirement of recognizing synonymous word and sentences. The problem of existing speech recognition model tiring to solve are that give a voice stream then output most likely sentence, while the speech tracking problem are that give a voice stream and speech note, then output the location of the voice stream. One direct way can solve that problem is using a hidden Markov model to build a voice stream classifier, but build classifiers for each document are too expansive, and I also can’t make sure its robustness. The other way is recognizing word then compare with word distribution, to achieve the objective of recognize the words of specking, there are two state of arts models those are seq2seq model and DFSMN model. The seq2seq model is using encoder-decoder and attention approach that can direct transfer speech sequence to text sequence, but it’s usually requires more computer resources than traditional model due to its high volume of parameters, but use CNN can speed up its calculation. (Gehring et al. 2017) While the DFSMN is an improvement of FNN approach, it has the advantage of low latency and small size for real-time applications. (Zhang et al. 2018) In this case, it’s worth noting that Wu’s approach (2018) had use term frequency–inverse document frequency (TFIDF) filter out the low frequency words as anchors of document, which was got very accurate result even change the order of sentence, which means that speech tracking is unnecessary to recognize full-sentence even not full words, only use the acoustic model in DFSMN also likely feasible. Obviously, minus the task of the model can further decrease the latency of tracking speech."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research project \n",
    "In this section, I will summarize the main point and the plan for this project.\n",
    "\n",
    "## Significance\n",
    "As I mentioned at the beginning, there is a requirement of speech reminder for the people who need to speech but not good at it. But the existing approaches all have their own limitation in flexibility and latency, and I identified that the speech recognition models of existing approaches used are deal with different problem than tracking speech voice stream in a given content, to direct deal with actual problem may simplifier and speed up existing models. So, there is important to develop a specific model for tracking speech voice stream in a given content, and to deal with the problem of synonymous words or sentences to improve flexibility, then we can use this model to develop an application which can helps user to do a better speech.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innovation\n",
    "The main innovation of this project is using machine leaning models to solve a common problem of hard to speech which have not an intelligent solution, with this intelligent solution users can reduce the time cost on find note when they are stuck in speech. And In order to achieve the goal, there are many innovations for achieve each function, such as that develop an specific model for tracking speech content rather than circle around using speech to text model then tracking speech by result of it, that innovation is aim to speed up the model and reduce the delay to make a better usability for users. Another one is that use the word2vec technique transfer text words to vector rather than direct use word texts to make the anchor in the document, which makes application can do the semantics similarity match when tracking speech to allows user not mandatory exactly follow with the speech note that bring a sense of flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of the Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Gehring, J., Auli, M., Grangier, D., Yarats, D. & Dauphin, Y.N. 2017, 'Convolutional sequence to sequence learning', JMLR. org, pp. 1243-52.\n",
    "\n",
    "Zhang, S., Lei, M., Yan, Z. & Dai, L. 2018, 'Deep-FSMN for large vocabulary continuous speech recognition', IEEE, pp. 5869-73.\n",
    "\n",
    "Gales, M.J., 1998. Maximum likelihood linear transformations for HMM-based speech recognition. Computer speech & language, 12(2), pp.75-98.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "246px",
    "width": "307px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
